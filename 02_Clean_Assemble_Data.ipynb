{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "69b9a648-bcc7-490d-9f9b-ea244d156bd6"
   },
   "source": [
    "# 02. Assemble and Clean Data for Classification Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import regex as re\n",
    "from nltk.corpus import stopwords \n",
    "np.random.seed(42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A. Assembly Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "focus": false,
    "id": "783fd153-28ac-47ab-bfca-27e7c1de95b4"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "df_a=pd.read_csv('./DebateEvolution.csv')\n",
    "df_a_com=pd.read_csv('./DebateEvolutionComments.csv')\n",
    "\n",
    "\n",
    "df_b=pd.read_csv('./Creation.csv')\n",
    "df_b_com=pd.read_csv('./CreationComments.csv')\n",
    "\n",
    "df_c=pd.read_csv('./Prochoice.csv')\n",
    "df_c_com=pd.read_csv('./ProchoiceComments.csv')\n",
    "\n",
    "df_d=pd.read_csv('./Prolife.csv')\n",
    "df_d_com=pd.read_csv('./ProlifeComments.csv')\n",
    "\n",
    "df_e=pd.read_csv('./general.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine(df, df_com):\n",
    "    \n",
    "    # Combine comment table and submission table\n",
    "    df = df[['title', 'score', 'selftext', 'timestamp']]\n",
    "    df_com = df_com[['body', 'score', 'timestamp']]\n",
    "    df = df.rename(columns={'selftext':'body'})\n",
    "    result = pd.concat([df, df_com], ignore_index=True)\n",
    "    \n",
    "    # Fill in missing value with empty strings\n",
    "    result['body']=result['body'].fillna(\"\")\n",
    "    result['title']=result['title'].fillna(\"\")\n",
    "    \n",
    "    # Combine titles with body text\n",
    "    result['body']=result['title']+\" \"+result['body']\n",
    "    result=result[['body', 'score', 'timestamp']]\n",
    "      \n",
    "    # Drop any rows that have any null values\n",
    "    result.dropna(inplace=True)\n",
    "    \n",
    "    # Drop any rows for which the body text was removed by Reddit\n",
    "    result=result.loc[result['body']!='[removed]']\n",
    "    \n",
    "    # \n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merging submissions and comment tables\n",
    "\n",
    "debate_evolution=combine(df_a, df_a_com)\n",
    "\n",
    "creation=combine(df_b, df_b_com)\n",
    "\n",
    "prochoice=combine(df_c, df_c_com)\n",
    "\n",
    "prolife=combine(df_d, df_d_com)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mix together the pairs of subreddits\n",
    "\n",
    "debate_evolution['class']=0\n",
    "creation['class']=1\n",
    "evol_debate = pd.concat([debate_evolution, creation], ignore_index=True)\n",
    "\n",
    "prochoice['class']=0\n",
    "prolife['class']=1\n",
    "abort_debate=pd.concat([prochoice, prolife], ignore_index=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_e=df_e[['title', 'subreddit', 'num_comments', 'created_utc']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_e['elapsed']=df_e['created_utc'].max()-df_e['created_utc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score(x):\n",
    "    thresh=df_e['num_comments'].median()\n",
    "    if x >= thresh:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "df_e['class']=df_e['num_comments'].apply(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "169.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_e['num_comments'].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    7.000000e+03\n",
       "mean     5.668239e+05\n",
       "std      3.483431e+05\n",
       "min      0.000000e+00\n",
       "25%      2.637520e+05\n",
       "50%      5.666920e+05\n",
       "75%      8.688822e+05\n",
       "max      1.133614e+06\n",
       "Name: elapsed, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_e['elapsed'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Credit to Harsha G. for thinking of engineering a title length feature!\n",
    "\n",
    "df_e['title_length']=df_e['title'].str.split().map(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    5790\n",
       "1    1210\n",
       "Name: feature_question, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Thanks to Ben for suggesting this feature engineering in class\n",
    "\n",
    "df_e['feature_question']=df_e['title'].str.contains(\"?\", regex=False)\n",
    "\n",
    "df_e['feature_question']=df_e['feature_question'].map({True: 1, False: 0})\n",
    "\n",
    "df_e[\"feature_question\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    6521\n",
       "1     479\n",
       "Name: feature_exclaim, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df_e['feature_exclaim']=df_e['title'].str.contains(\"!\", regex=False)\n",
    "\n",
    "df_e['feature_exclaim']=df_e['feature_exclaim'].map({True: 1, False: 0})\n",
    "\n",
    "df_e[\"feature_exclaim\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B. Cleaning the Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function adapted from General Assembly Notebook for NLP\n",
    "\n",
    "def review_to_words(raw_review):\n",
    "\n",
    "    # 1. Remove non-letters        \n",
    "    letters_only = re.sub(\"[^a-zA-Z]\", \" \", raw_review)\n",
    "    #\n",
    "    # 2. Convert to lower case, split into individual words\n",
    "    words = letters_only.lower().split()\n",
    "    #\n",
    "    # 3. In Python, searching a set is much faster than searching\n",
    "    #   a list, so convert the stop words to a set\n",
    "    stops = set(stopwords.words('english'))\n",
    "    # \n",
    "    # 5. Remove stop words\n",
    "    meaningful_words = [w for w in words if not w in stops]\n",
    "    \n",
    "    return(\" \".join(meaningful_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_e['title']=df_e['title'].apply(review_to_words)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "evol_debate['body']=evol_debate['body'].apply(review_to_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "abort_debate['body']=abort_debate['body'].apply(review_to_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping messages that refer to 'removed', because I don't want to classify\n",
    "# based on the extent to which Reddit is engaged in automated troll removal\n",
    "\n",
    "evol_debate=evol_debate.loc[~evol_debate['body'].str.contains(\"removed\")]\n",
    "abort_debate=abort_debate.loc[~abort_debate['body'].str.contains(\"removed\")]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_e.to_pickle('./general_pickle')\n",
    "evol_debate.to_pickle('./evol_pickle')\n",
    "abort_debate.to_pickle('./abort_pickle')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "abort_debate.loc[abort_debate['class']==0]['body'].to_csv('./prochoice_text.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "abort_debate.loc[abort_debate['class']==1]['body'].to_csv('./prolife_text.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "evol_debate.loc[evol_debate['class']==0]['body'].to_csv('./evolution_text.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "evol_debate.loc[evol_debate['class']==1]['body'].to_csv('./creation_text.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
