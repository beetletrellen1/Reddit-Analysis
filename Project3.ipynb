{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "69b9a648-bcc7-490d-9f9b-ea244d156bd6"
   },
   "source": [
    "# Web Scraping for Reddit & Predicting Comments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-23T19:28:02.619411Z",
     "start_time": "2017-10-23T19:28:02.600856Z"
    }
   },
   "source": [
    "In this project, we will practice two major skills. Collecting data by scraping a website and then building a binary predictor.\n",
    "\n",
    "As we discussed in week 2, and earlier today, there are two components to starting a data science problem: the problem statement, and acquiring the data.\n",
    "\n",
    "For this article, your problem statement will be: _What characteristics of a post on Reddit contribute most to the overall interaction (as measured by number of comments)?_\n",
    "\n",
    "Your method for acquiring the data will be scraping the 'hot' threads as listed on the [Reddit homepage](https://www.reddit.com/). You'll acquire _AT LEAST FOUR_ pieces of information about each thread:\n",
    "1. The title of the thread\n",
    "2. The subreddit that the thread corresponds to\n",
    "3. The length of time it has been up on Reddit\n",
    "4. The number of comments on the thread\n",
    "\n",
    "Once you've got the data, you will build a classification model that, using Natural Language Processing and any other relevant features, predicts whether or not a given Reddit post will have above or below the _median_ number of comments.\n",
    "\n",
    "**BONUS PROBLEMS**\n",
    "1. If creating a logistic regression, GridSearch Ridge and Lasso for this model and report the best hyperparameter values.\n",
    "1. Scrape the actual text of the threads using Selenium (you'll learn about this in Webscraping II).\n",
    "2. Write the actual article that you're pitching and turn it into a blog post that you host on your personal website."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "a948d79c-5527-4c0d-ab23-f5d43ce72056"
   },
   "source": [
    "### Scraping Thread Info from Reddit.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set up a request (using requests) to the URL below. Use BeautifulSoup to parse the page and extract all results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While this has some more verbose elements removed, we can see that there is some structure to the above:\n",
    "- The thread title is within an `<a>` tag with the attribute `data-event-action=\"title\"`.\n",
    "- The time since the thread was created is within a `<time>` tag with attribute `class=\"live-timestamp\"`.\n",
    "- The subreddit is within an `<a>` tag with the attribute `class=\"subreddit hover may-blank\"`.\n",
    "- The number of comments is within an `<a>` tag with the attribute data-event-action=\"comments\"`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "\n",
    "# To download the service files for the tokenizer\n",
    "#nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now, let's put it all together.\n",
    "\n",
    "Use the functions you wrote above to parse out the 4 fields - title, time, subreddit, and number of comments. Create a dataframe from the results with those 4 columns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "43e71edd-210e-42b1-9336-70a931f048af"
   },
   "source": [
    "### Save your results as a CSV\n",
    "You may do this regularly while scraping data as well, so that if your scraper stops of your computer crashes, you don't lose all your data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "focus": false,
    "id": "783fd153-28ac-47ab-bfca-27e7c1de95b4"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "df_a=pd.read_csv('./DebateEvolution.csv')\n",
    "df_a_com=pd.read_csv('./DebateEvolutionComments.csv')\n",
    "\n",
    "df_b=pd.read_csv('./Creation.csv')\n",
    "df_b_com=pd.read_csv('./CreationComments.csv')\n",
    "\n",
    "df_c=pd.read_csv('./Prochoice.csv')\n",
    "df_c_com=pd.read_csv('./ProchoiceComments.csv')\n",
    "\n",
    "df_d=pd.read_csv('./Prolife.csv')\n",
    "df_d_com=pd.read_csv('./ProlifeComments.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine(df, df_com):\n",
    "    df = df[['title', 'score', 'selftext', 'timestamp']]\n",
    "    df_com = df_com[['body', 'score', 'timestamp']]\n",
    "    df = df.rename(columns={'selftext':'body'})\n",
    "    result = pd.concat([df, df_com], ignore_index=True)\n",
    "    result['body']=result['body'].fillna(\"\")\n",
    "    result['title']=result['title'].fillna(\"\")\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merging submissions and comment tables\n",
    "\n",
    "debate_evolution=combine(df_a, df_a_com)\n",
    "\n",
    "creation=combine(df_b, df_b_com)\n",
    "\n",
    "prochoice=combine(df_c, df_c_com)\n",
    "\n",
    "prolife=combine(df_d, df_d_com)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body</th>\n",
       "      <th>score</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>2018-03-22 18:27:38</td>\n",
       "      <td>Evolution is a joke!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mathematics has been described as **unreasonab...</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-03-22 06:10:32</td>\n",
       "      <td>Is Evolution unreasonably effective?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Just checked over on /r/creation, and found th...</td>\n",
       "      <td>16</td>\n",
       "      <td>2018-03-19 09:40:16</td>\n",
       "      <td>It's hard to take seriously a subreddit which ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://www.reddit.com/r/askscience/comments/8...</td>\n",
       "      <td>3</td>\n",
       "      <td>2018-03-17 16:34:54</td>\n",
       "      <td>Interesting comment bu u/danby explaining comm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I told my creationist friend about this: https...</td>\n",
       "      <td>3</td>\n",
       "      <td>2018-03-17 01:41:23</td>\n",
       "      <td>Does this example of speciation “not count?”</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                body score  \\\n",
       "0                                                        1   \n",
       "1  Mathematics has been described as **unreasonab...     0   \n",
       "2  Just checked over on /r/creation, and found th...    16   \n",
       "3  https://www.reddit.com/r/askscience/comments/8...     3   \n",
       "4  I told my creationist friend about this: https...     3   \n",
       "\n",
       "             timestamp                                              title  \n",
       "0  2018-03-22 18:27:38                               Evolution is a joke!  \n",
       "1  2018-03-22 06:10:32               Is Evolution unreasonably effective?  \n",
       "2  2018-03-19 09:40:16  It's hard to take seriously a subreddit which ...  \n",
       "3  2018-03-17 16:34:54  Interesting comment bu u/danby explaining comm...  \n",
       "4  2018-03-17 01:41:23       Does this example of speciation “not count?”  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "debate_evolution.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                                      []\n",
       "1       [Mathematics, has, been, described, as, **unre...\n",
       "2       [Just, checked, over, on, /r/creation, ,, and,...\n",
       "3       [https, :, //www.reddit.com/r/askscience/comme...\n",
       "4       [I, told, my, creationist, friend, about, this...\n",
       "5       [I, often, hear, “, cdesign, proponentists, ”,...\n",
       "6       [Oh, this, is, a, good, one, ., This, is, u/jo...\n",
       "7       [IrrationalIrritation, and, I, agreed, here, :...\n",
       "8       [https, :, //youtu.be/6jrguc_oXuA, Script, :, ...\n",
       "9       [[, Paper, ., ], (, http, :, //www.cell.com/aj...\n",
       "10      [I, have, heard, creationists, say, that, if, ...\n",
       "11      [https, :, //youtu.be/gEKltaQ5HlA, This, is, a...\n",
       "12      [How, did, Noah, get, the, tyrannosaurus, in, ...\n",
       "13      [I, have, often, seen, many, advocates, of, ev...\n",
       "14      [I, do, n't, know, if, this, is, a, new, thing...\n",
       "15      [In, my, previous, post, on, genetic, entropy,...\n",
       "16      [Hey, everyone, ., Thankyou, for, your, time, ...\n",
       "17      [Let, 's, say, there, was, a, hypothetical, pe...\n",
       "18      [In, the, book, ,, ``, What, Scientists, Think...\n",
       "19      [The, A, critical, look, at, Intelligent, Desi...\n",
       "20      [So, I, ’, m, a, biologist, ,, and, I, married...\n",
       "21      [Found, this, fun, little, project, and, thoug...\n",
       "22      [Here, Evolution, News, attempt, to, debunked,...\n",
       "23      [I, consider, myself, right, wing, and, I, sup...\n",
       "24      [[, Link, to, full, thread, ], (, https, :, //...\n",
       "25      [I, thought, I, would, introduce, you, to, ano...\n",
       "26      [I, just, was, pointed, to, this, subreddid, i...\n",
       "27                                        [[, deleted, ]]\n",
       "28      [This, is, an, auto-post, for, the, Monthly, Q...\n",
       "29      [For, example, ,, I, often, hear, the, claim, ...\n",
       "                              ...                        \n",
       "5414    [``, Word, salad, '', is, a, phrase, internet,...\n",
       "5415    [Okay, ,, I, literally, do, n't, know, what, p...\n",
       "5416    [&, gt, ;, Human, =, Homo, sapiens, ,, From, W...\n",
       "5417    [What, on, earth, are, you, trying, to, argue,...\n",
       "5418    [&, gt, ;, Okay, ..., and, Homo, sapiens, is, ...\n",
       "5419                                     [Word, salad, .]\n",
       "5420    [Evolution, is, not, a, theory, ,, it, is, wel...\n",
       "5421    [Okay, ..., and, Homo, sapiens, is, about, 2-3...\n",
       "5422    [Oh, man, ,, I, 'm, and, evolution, guy, too, ...\n",
       "5423                         [Please, stop, ., Please, .]\n",
       "5424    [Reading, your, answer, ,, I, can, only, concl...\n",
       "5425    [&, gt, ;, We, do, see, it, as, worthwhile, by...\n",
       "5426    [&, gt, ;, Already, answered, and, completely,...\n",
       "5427    [Let, 's, take, the, case, of, a, rock, with, ...\n",
       "5428    [I, appreciate, that, ., I, 'd, be, open, to, ...\n",
       "5429    [From, earlier, discussion, that, includes, a,...\n",
       "5430    [That, 's, not, true, ., Homo, sapiens, are, 2...\n",
       "5431    [Evolution, is, the, change, in, the, genetic,...\n",
       "5432    [Trick, question, :, they, 're, both, modern, ...\n",
       "5433    [More, :, &, gt, ;, ``, But, on, the, chimpanz...\n",
       "5434         [What, is, the, point, of, the, question, ?]\n",
       "5435    [This, is, /r/DebateEvolution, -, **NOT, GOOGL...\n",
       "5436    [&, gt, ;, [, Chimps, !, !, ], I, do, n't, thi...\n",
       "5437    [[, [, Chimps, !, !, ], ], (, http, :, //bible...\n",
       "5438    [If, a, piece, of, evidence, were, to, be, fou...\n",
       "5439    [&, gt, ;, As, chimpanzees, evolved, ,, how, m...\n",
       "5440    [In, case, anyone, is, n't, sure, of, how, sci...\n",
       "5441    [The, rate, of, mutation, for, chimpanzees, is...\n",
       "5442    [Why, do, n't, you, go, count, them, ?, It, wo...\n",
       "5443    [Oh, I, know, ,, I, remember, who, you, are, -...\n",
       "Name: body, Length: 5444, dtype: object"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#debate_evolution['body'].map(word_tokenize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "04563b69-f7b6-466f-9d65-fc62c9ddee6a"
   },
   "source": [
    "## Predicting comments using Random Forests + Another Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "243e949e-2742-40af-872e-fec475fd306c"
   },
   "source": [
    "#### Load in the the data of scraped results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "focus": false,
    "id": "588f9845-6143-4bcc-bfd1-85d45b79303d"
   },
   "outputs": [],
   "source": [
    "## YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "c7631f51-07f2-4c79-a093-3e9bc7849a48"
   },
   "source": [
    "#### We want to predict a binary variable - whether the number of comments was low or high. Compute the median number of comments and create a new binary variable that is true when the number of comments is high (above the median)\n",
    "\n",
    "We could also perform Linear Regression (or any regression) to predict the number of comments here. Instead, we are going to convert this into a _binary_ classification problem, by predicting two classes, HIGH vs LOW number of comments.\n",
    "\n",
    "While performing regression may be better, performing classification may help remove some of the noise of the extremely popular threads. We don't _have_ to choose the `median` as the splitting point - we could also split on the 75th percentile or any other reasonable breaking point.\n",
    "\n",
    "In fact, the ideal scenario may be to predict many levels of comment numbers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "focus": false,
    "id": "c20d2498-151c-44c3-a453-3a333c79a0ac"
   },
   "outputs": [],
   "source": [
    "## YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "a7afb2c0-d41e-4779-8216-91cd8dd4473f"
   },
   "source": [
    "#### Thought experiment: What is the baseline accuracy for this model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "focus": false,
    "id": "87a17d3d-b7f4-4747-9f75-f9af1d18a174"
   },
   "outputs": [],
   "source": [
    "## YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "4fb29de2-5b98-474c-a4ad-5170b72b9aea"
   },
   "source": [
    "#### Create a Random Forest model to predict High/Low number of comments using Sklearn. Start by ONLY using the subreddit as a feature. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "focus": false,
    "id": "ddbc6159-6854-4ca7-857f-bfecdaf6d9c2"
   },
   "outputs": [],
   "source": [
    "## YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "0ef04f32-419c-4bf2-baf7-48201f03df89"
   },
   "source": [
    "#### Create a few new variables in your dataframe to represent interesting features of a thread title.\n",
    "- For example, create a feature that represents whether 'cat' is in the title or whether 'funny' is in the title. \n",
    "- Then build a new Random Forest with these features. Do they add any value?\n",
    "- After creating these variables, use count-vectorizer to create features based on the words in the thread titles.\n",
    "- Build a new random forest model with subreddit and these new features included."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "## YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "9367beff-72ba-4768-a0ba-a50b335de61d"
   },
   "source": [
    "#### Use cross-validation in scikit-learn to evaluate the model above. \n",
    "- Evaluate the accuracy of the model, as well as any other metrics you feel are appropriate. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "focus": false,
    "id": "269b9e7c-60b5-4a06-8255-881d7395bc1b"
   },
   "outputs": [],
   "source": [
    "## YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Repeat the model-building process with a non-tree-based method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "## YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "db045898-1d2d-4af2-8e79-437c4c7546b4"
   },
   "source": [
    "#### Use Count Vectorizer from scikit-learn to create features from the thread titles. \n",
    "- Examine using count or binary features in the model\n",
    "- Re-evaluate your models using these. Does this improve the model performance? \n",
    "- What text features are the most valuable? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "## YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Executive Summary\n",
    "---\n",
    "Put your executive summary in a Markdown cell below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "3be94357-e551-4094-b784-2df039216d33"
   },
   "source": [
    "### BONUS\n",
    "Refer to the README for the bonus parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "focus": false,
    "id": "4239e458-28bd-4675-8db3-c1d9c02b9854"
   },
   "outputs": [],
   "source": [
    "## YOUR CODE HERE"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
